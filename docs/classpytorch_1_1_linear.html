<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>pytorch-inference: pytorch::Linear Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">pytorch-inference
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classpytorch_1_1_linear.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classpytorch_1_1_linear-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">pytorch::Linear Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="_linear_8hpp_source.html">Linear.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for pytorch::Linear:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classpytorch_1_1_linear.png" usemap="#pytorch::Linear_map" alt=""/>
  <map id="pytorch::Linear_map" name="pytorch::Linear_map">
<area href="classpytorch_1_1_layer.html" alt="pytorch::Layer" shape="rect" coords="0,0,97,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a47740884c0ce199daecd9958bd6b6ca3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a47740884c0ce199daecd9958bd6b6ca3">Linear</a> (const af::array &amp;<a class="el" href="classpytorch_1_1_linear.html#a1ce5755565afc4f3de332e3f6836f3bd">weights</a>, const af::array &amp;<a class="el" href="classpytorch_1_1_linear.html#ae2ec81120db6e196709dc11a67fc9ce8">bias</a>)</td></tr>
<tr class="memdesc:a47740884c0ce199daecd9958bd6b6ca3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object given weights, and bias tensors.  <a href="#a47740884c0ce199daecd9958bd6b6ca3">More...</a><br /></td></tr>
<tr class="separator:a47740884c0ce199daecd9958bd6b6ca3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad061ae2fec18baa95cc7b9b854b57f92"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#ad061ae2fec18baa95cc7b9b854b57f92">Linear</a> (const std::string &amp;weights_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;weights_dims={}, const bool <a class="el" href="classpytorch_1_1_linear.html#af77334f2b9d31c019e91834651dd5fe4">has_bias</a>=false, const std::string &amp;bias_filename=&quot;&quot;, const std::vector&lt; int &gt; &amp;bias_dims={}, const std::string &amp;python_home=&quot;../scripts&quot;)</td></tr>
<tr class="memdesc:ad061ae2fec18baa95cc7b9b854b57f92"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructs a <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object given the filenames and sizes of the requisite tensors.  <a href="#ad061ae2fec18baa95cc7b9b854b57f92">More...</a><br /></td></tr>
<tr class="separator:ad061ae2fec18baa95cc7b9b854b57f92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac8bbc9c901cda2e77ac60abccf4de372"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#ac8bbc9c901cda2e77ac60abccf4de372">Linear</a> (const <a class="el" href="classpytorch_1_1_linear.html">Linear</a> &amp;other)</td></tr>
<tr class="memdesc:ac8bbc9c901cda2e77ac60abccf4de372"><td class="mdescLeft">&#160;</td><td class="mdescRight">Copy constructor, constructs another <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object that is an exact copy of the argument.  <a href="#ac8bbc9c901cda2e77ac60abccf4de372">More...</a><br /></td></tr>
<tr class="separator:ac8bbc9c901cda2e77ac60abccf4de372"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b0abcb252baef05e13f648df24af1cf"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a2b0abcb252baef05e13f648df24af1cf">~Linear</a> ()</td></tr>
<tr class="memdesc:a2b0abcb252baef05e13f648df24af1cf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor - for now trivial, may need to take on some functionality.  <a href="#a2b0abcb252baef05e13f648df24af1cf">More...</a><br /></td></tr>
<tr class="separator:a2b0abcb252baef05e13f648df24af1cf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8cbffb226f756dfabc3fcbb80c075cef"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a8cbffb226f756dfabc3fcbb80c075cef">add_weights</a> (const std::string &amp;weights_filename, const std::vector&lt; int &gt; &amp;weights_dims)</td></tr>
<tr class="memdesc:a8cbffb226f756dfabc3fcbb80c075cef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Read in weights from a file given here if it wasn't passed to the constructor. Overwrites current contents of this-&gt;weights.  <a href="#a8cbffb226f756dfabc3fcbb80c075cef">More...</a><br /></td></tr>
<tr class="separator:a8cbffb226f756dfabc3fcbb80c075cef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4db382b11a3f91778797a6e940692d86"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a4db382b11a3f91778797a6e940692d86">add_bias</a> (const std::string &amp;bias_filename, const std::vector&lt; int &gt; &amp;bias_dims)</td></tr>
<tr class="memdesc:a4db382b11a3f91778797a6e940692d86"><td class="mdescLeft">&#160;</td><td class="mdescRight">Read in bias from a file given here if it wasn't passed to the constructor. Overwrites current contents of this-&gt;bias.  <a href="#a4db382b11a3f91778797a6e940692d86">More...</a><br /></td></tr>
<tr class="separator:a4db382b11a3f91778797a6e940692d86"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a850c81192d2f73e96f42700b94091a57"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a850c81192d2f73e96f42700b94091a57">set_has_bias</a> (bool <a class="el" href="classpytorch_1_1_linear.html#af77334f2b9d31c019e91834651dd5fe4">has_bias</a>)</td></tr>
<tr class="memdesc:a850c81192d2f73e96f42700b94091a57"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets whether or not this layer has bias. If no, then this should be called. Otherwise, it's unnecessary.  <a href="#a850c81192d2f73e96f42700b94091a57">More...</a><br /></td></tr>
<tr class="separator:a850c81192d2f73e96f42700b94091a57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b0318a61558f674bff2be8410da1fb5"><td class="memItemLeft" align="right" valign="top">std::vector&lt; af::array &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a0b0318a61558f674bff2be8410da1fb5">forward</a> (const std::vector&lt; af::array &gt; &amp;input)</td></tr>
<tr class="memdesc:a0b0318a61558f674bff2be8410da1fb5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward function, takes data and performs the <a class="el" href="classpytorch_1_1_linear.html">Linear</a> operation using the already-initialized weights and bias tensors.  <a href="#a0b0318a61558f674bff2be8410da1fb5">More...</a><br /></td></tr>
<tr class="separator:a0b0318a61558f674bff2be8410da1fb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d86c19268604c3c35a7958bb55d0329"><td class="memItemLeft" align="right" valign="top">std::vector&lt; af::array &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a6d86c19268604c3c35a7958bb55d0329">operator()</a> (const std::vector&lt; af::array &gt; &amp;input)</td></tr>
<tr class="memdesc:a6d86c19268604c3c35a7958bb55d0329"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward function, takes data and performs the <a class="el" href="classpytorch_1_1_linear.html">Linear</a> operation using the already-initialized weights and bias tensors.  <a href="#a6d86c19268604c3c35a7958bb55d0329">More...</a><br /></td></tr>
<tr class="separator:a6d86c19268604c3c35a7958bb55d0329"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a1ce5755565afc4f3de332e3f6836f3bd"><td class="memItemLeft" align="right" valign="top">af::array&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#a1ce5755565afc4f3de332e3f6836f3bd">weights</a></td></tr>
<tr class="separator:a1ce5755565afc4f3de332e3f6836f3bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae2ec81120db6e196709dc11a67fc9ce8"><td class="memItemLeft" align="right" valign="top">af::array&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#ae2ec81120db6e196709dc11a67fc9ce8">bias</a></td></tr>
<tr class="separator:ae2ec81120db6e196709dc11a67fc9ce8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae1e4c23bdc871fa3df2d6fc1db4cf954"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classpycpp_1_1py__object.html">pycpp::py_object</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#ae1e4c23bdc871fa3df2d6fc1db4cf954">utils</a></td></tr>
<tr class="separator:ae1e4c23bdc871fa3df2d6fc1db4cf954"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af77334f2b9d31c019e91834651dd5fe4"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classpytorch_1_1_linear.html#af77334f2b9d31c019e91834651dd5fe4">has_bias</a></td></tr>
<tr class="separator:af77334f2b9d31c019e91834651dd5fe4"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a47740884c0ce199daecd9958bd6b6ca3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47740884c0ce199daecd9958bd6b6ca3">&#9670;&nbsp;</a></span>Linear() <span class="overload">[1/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">pytorch::Linear::Linear </td>
          <td>(</td>
          <td class="paramtype">const af::array &amp;&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const af::array &amp;&#160;</td>
          <td class="paramname"><em>bias</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object given weights, and bias tensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weights</td><td>The trained weight tensors. For those comfortable with Py_Cpp. </td></tr>
    <tr><td class="paramname">bias</td><td>The trained bias tensors. For those comfortable with Py_Cpp. Can be initialized to zero. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ad061ae2fec18baa95cc7b9b854b57f92"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad061ae2fec18baa95cc7b9b854b57f92">&#9670;&nbsp;</a></span>Linear() <span class="overload">[2/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">pytorch::Linear::Linear </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>weights_filename</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>weights_dims</em> = <code>{}</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const bool&#160;</td>
          <td class="paramname"><em>has_bias</em> = <code>false</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>bias_filename</em> = <code>&quot;&quot;</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias_dims</em> = <code>{}</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>python_home</em> = <code>&quot;../scripts&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Constructs a <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object given the filenames and sizes of the requisite tensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weights_filename</td><td>The file where the weights tensor is saved. Will be loaded with torch.load(filename). </td></tr>
    <tr><td class="paramname">weights_dims</td><td>The dimensions of the weights tensor in pytorch convention - (batch, channels, h, w) </td></tr>
    <tr><td class="paramname">bias_filename</td><td>The file where the bias tensor is saved. Will be loaded with torch.load(filename). </td></tr>
    <tr><td class="paramname">bias_dims</td><td>The dimensions of the bias tensor in pytorch convention - (batch, channels, h, w) </td></tr>
    <tr><td class="paramname">python_home</td><td>Where the utility scripts are - holds the loading script necessary to load up the tensors. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="ac8bbc9c901cda2e77ac60abccf4de372"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac8bbc9c901cda2e77ac60abccf4de372">&#9670;&nbsp;</a></span>Linear() <span class="overload">[3/3]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">pytorch::Linear::Linear </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classpytorch_1_1_linear.html">Linear</a> &amp;&#160;</td>
          <td class="paramname"><em>other</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Copy constructor, constructs another <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object that is an exact copy of the argument. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">other</td><td>Another <a class="el" href="classpytorch_1_1_linear.html">Linear</a> object to copy. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a2b0abcb252baef05e13f648df24af1cf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2b0abcb252baef05e13f648df24af1cf">&#9670;&nbsp;</a></span>~Linear()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual pytorch::Linear::~Linear </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Destructor - for now trivial, may need to take on some functionality. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a4db382b11a3f91778797a6e940692d86"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4db382b11a3f91778797a6e940692d86">&#9670;&nbsp;</a></span>add_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void pytorch::Linear::add_bias </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>bias_filename</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>bias_dims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Read in bias from a file given here if it wasn't passed to the constructor. Overwrites current contents of this-&gt;bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bias_filename</td><td>The file where the bias tensor is saved. Will be loaded with torch.load(filename). </td></tr>
    <tr><td class="paramname">bias_dims</td><td>The dimensions of the bias tensor in pytorch convention - (batch, channels, h, w) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a8cbffb226f756dfabc3fcbb80c075cef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8cbffb226f756dfabc3fcbb80c075cef">&#9670;&nbsp;</a></span>add_weights()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void pytorch::Linear::add_weights </td>
          <td>(</td>
          <td class="paramtype">const std::string &amp;&#160;</td>
          <td class="paramname"><em>weights_filename</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; int &gt; &amp;&#160;</td>
          <td class="paramname"><em>weights_dims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Read in weights from a file given here if it wasn't passed to the constructor. Overwrites current contents of this-&gt;weights. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">weights_filename</td><td>The file where the weights tensor is saved. Will be loaded with torch.load(filename). </td></tr>
    <tr><td class="paramname">weights_dims</td><td>The dimensions of the weights tensor in pytorch convention - (batch, channels, h, w) </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a0b0318a61558f674bff2be8410da1fb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0b0318a61558f674bff2be8410da1fb5">&#9670;&nbsp;</a></span>forward()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;af::array&gt; pytorch::Linear::forward </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; af::array &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Forward function, takes data and performs the <a class="el" href="classpytorch_1_1_linear.html">Linear</a> operation using the already-initialized weights and bias tensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input data size (dims_in, 1, 1, batch) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Transformed data size (dims_out, 1, batch) </dd></dl>

<p>Implements <a class="el" href="classpytorch_1_1_layer.html#a1abb45857b18f70a9a95ae16a69f968d">pytorch::Layer</a>.</p>

</div>
</div>
<a id="a6d86c19268604c3c35a7958bb55d0329"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6d86c19268604c3c35a7958bb55d0329">&#9670;&nbsp;</a></span>operator()()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;af::array&gt; pytorch::Linear::operator() </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; af::array &gt; &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Forward function, takes data and performs the <a class="el" href="classpytorch_1_1_linear.html">Linear</a> operation using the already-initialized weights and bias tensors. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>Input data size (dims_in, 1, 1, batch) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Transformed data size (dims_out, 1, batch) </dd></dl>

<p>Implements <a class="el" href="classpytorch_1_1_layer.html#a7a766ac20be5e818e497e6f2f05a2c8d">pytorch::Layer</a>.</p>

</div>
</div>
<a id="a850c81192d2f73e96f42700b94091a57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a850c81192d2f73e96f42700b94091a57">&#9670;&nbsp;</a></span>set_has_bias()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void pytorch::Linear::set_has_bias </td>
          <td>(</td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>has_bias</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets whether or not this layer has bias. If no, then this should be called. Otherwise, it's unnecessary. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">has_bias</td><td>Whether or not the layer has bias. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ae2ec81120db6e196709dc11a67fc9ce8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae2ec81120db6e196709dc11a67fc9ce8">&#9670;&nbsp;</a></span>bias</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">af::array pytorch::Linear::bias</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="af77334f2b9d31c019e91834651dd5fe4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af77334f2b9d31c019e91834651dd5fe4">&#9670;&nbsp;</a></span>has_bias</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool pytorch::Linear::has_bias</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ae1e4c23bdc871fa3df2d6fc1db4cf954"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae1e4c23bdc871fa3df2d6fc1db4cf954">&#9670;&nbsp;</a></span>utils</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classpycpp_1_1py__object.html">pycpp::py_object</a> pytorch::Linear::utils</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a1ce5755565afc4f3de332e3f6836f3bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ce5755565afc4f3de332e3f6836f3bd">&#9670;&nbsp;</a></span>weights</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">af::array pytorch::Linear::weights</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="_linear_8hpp_source.html">Linear.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacepytorch.html">pytorch</a></li><li class="navelem"><a class="el" href="classpytorch_1_1_linear.html">Linear</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
